{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np\nfrom glob import glob\nimport PIL\nimport matplotlib.pyplot as plt\nimport warnings\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:18:25.277055Z","iopub.execute_input":"2023-09-24T14:18:25.277834Z","iopub.status.idle":"2023-09-24T14:18:25.284001Z","shell.execute_reply.started":"2023-09-24T14:18:25.277780Z","shell.execute_reply":"2023-09-24T14:18:25.282954Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Get the dataset\n\nThe LoL Dataset has been created for low-light image enhancement. It provides 485 images for training and 15 for testing. Each image pair in the dataset consits of a low-light input image and its corresponding well-exposed reference image.","metadata":{}},{"cell_type":"code","source":"data = '/kaggle/input/lol-dataset/lol_dataset/'\nprint(os.listdir(data))","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:18:30.149873Z","iopub.execute_input":"2023-09-24T14:18:30.150238Z","iopub.status.idle":"2023-09-24T14:18:30.168585Z","shell.execute_reply.started":"2023-09-24T14:18:30.150208Z","shell.execute_reply":"2023-09-24T14:18:30.167305Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['eval15', 'our485']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creating a Tensorflow Dataset\n\nWe use 300 image pairs from the LoL Dataset's training set for training, and we use the remaining 185 image pairs for validation. We generate random crops of size 128 x 128 from the image pairs to be used for both training and validation.","metadata":{}},{"cell_type":"code","source":"random.seed(10)\nIMAGE_SIZE = 128\nBATCH_SIZE = 4\nMAX_TRAIN_IMAGES = 300","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:18:45.095951Z","iopub.execute_input":"2023-09-24T14:18:45.096334Z","iopub.status.idle":"2023-09-24T14:18:45.102079Z","shell.execute_reply.started":"2023-09-24T14:18:45.096303Z","shell.execute_reply":"2023-09-24T14:18:45.100558Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def read_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, channels=3)\n    image.set_shape([None, None, 3])\n    image = tf.cast(image, dtype=tf.float32) / 255.0\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:48:43.612330Z","iopub.execute_input":"2023-09-24T14:48:43.612718Z","iopub.status.idle":"2023-09-24T14:48:43.618575Z","shell.execute_reply.started":"2023-09-24T14:48:43.612687Z","shell.execute_reply":"2023-09-24T14:48:43.617408Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def random_crop(low_image, enhanced_image):\n    low_image_shape = tf.shape(low_image)[:2]\n    low_w = tf.random.uniform(\n        shape=(), maxval=low_image_shape[1] - IMAGE_SIZE + 1, dtype=tf.int32\n    )\n    low_h = tf.random.uniform(\n        shape=(), maxval=low_image_shape[0] - IMAGE_SIZE + 1, dtype=tf.int32\n    )\n    enhanced_w = low_w\n    enhanced_h = low_h\n    low_image_cropped = low_image[\n        low_h : low_h + IMAGE_SIZE, low_w : low_w + IMAGE_SIZE\n    ]\n    enhanced_image_cropped = enhanced_image[\n        enhanced_h : enhanced_h + IMAGE_SIZE, enhanced_w : enhanced_w + IMAGE_SIZE\n    ]\n    return low_image_cropped, enhanced_image_cropped","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:18:49.687296Z","iopub.execute_input":"2023-09-24T14:18:49.687699Z","iopub.status.idle":"2023-09-24T14:18:49.696150Z","shell.execute_reply.started":"2023-09-24T14:18:49.687667Z","shell.execute_reply":"2023-09-24T14:18:49.694632Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def load_data(low_light_image_path, enhanced_image_path):\n    low_light_image = read_image(low_light_image_path)\n    enhanced_image = read_image(enhanced_image_path)\n    low_light_image, enhanced_image = random_crop(low_light_image, enhanced_image)\n    return low_light_image, enhanced_image","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:52:34.126561Z","iopub.execute_input":"2023-09-24T14:52:34.127036Z","iopub.status.idle":"2023-09-24T14:52:34.132877Z","shell.execute_reply.started":"2023-09-24T14:52:34.126988Z","shell.execute_reply":"2023-09-24T14:52:34.131555Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def get_dataset(low_light_images, enhanced_images):\n    dataset = tf.data.Dataset.from_tensor_slices((low_light_images, enhanced_images))\n    dataset = dataset.map(load_data, num_parallel_calls = tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:18:54.353041Z","iopub.execute_input":"2023-09-24T14:18:54.353416Z","iopub.status.idle":"2023-09-24T14:18:54.359960Z","shell.execute_reply.started":"2023-09-24T14:18:54.353384Z","shell.execute_reply":"2023-09-24T14:18:54.358319Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of data","metadata":{}},{"cell_type":"code","source":"train_low_light_images = sorted(glob(\"/kaggle/input/lol-dataset/lol_dataset/our485/low/*\"))[:MAX_TRAIN_IMAGES]\ntrain_enhanced_images = sorted(glob(\"/kaggle/input/lol-dataset/lol_dataset/our485/high/*\"))[:MAX_TRAIN_IMAGES]\n\nval_low_light_images = sorted(glob(\"/kaggle/input/lol-dataset/lol_dataset/our485/low/*\"))[MAX_TRAIN_IMAGES:]\nval_enhanced_images = sorted(glob(\"/kaggle/input/lol-dataset/lol_dataset/our485/high/*\"))[MAX_TRAIN_IMAGES:]\n\ntest_low_light_images = sorted(glob(\"/kaggle/input/lol-dataset/lol_dataset/eval15/low/*\"))\ntest_enhanced_images = sorted(glob(\"/kaggle/input/lol-dataset/lol_dataset/eval15/high/*\"))","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:47:29.037745Z","iopub.execute_input":"2023-09-24T14:47:29.038217Z","iopub.status.idle":"2023-09-24T14:47:29.059846Z","shell.execute_reply.started":"2023-09-24T14:47:29.038180Z","shell.execute_reply":"2023-09-24T14:47:29.058811Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_dataset = get_dataset(train_low_light_images, train_enhanced_images)\nval_dataset = get_dataset(val_low_light_images, val_enhanced_images)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:52:38.001589Z","iopub.execute_input":"2023-09-24T14:52:38.002148Z","iopub.status.idle":"2023-09-24T14:52:38.296002Z","shell.execute_reply.started":"2023-09-24T14:52:38.002114Z","shell.execute_reply":"2023-09-24T14:52:38.294952Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"print(\"Train dataset: \", train_dataset)\nprint(\"Val dataset: \", val_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-24T14:53:21.759188Z","iopub.execute_input":"2023-09-24T14:53:21.759567Z","iopub.status.idle":"2023-09-24T14:53:21.766062Z","shell.execute_reply.started":"2023-09-24T14:53:21.759518Z","shell.execute_reply":"2023-09-24T14:53:21.764831Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Train dataset:  <_BatchDataset element_spec=(TensorSpec(shape=(4, None, None, 3), dtype=tf.float32, name=None), TensorSpec(shape=(4, None, None, 3), dtype=tf.float32, name=None))>\nVal dataset:  <_BatchDataset element_spec=(TensorSpec(shape=(4, None, None, 3), dtype=tf.float32, name=None), TensorSpec(shape=(4, None, None, 3), dtype=tf.float32, name=None))>\n","output_type":"stream"}]}]}